{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from torchtext.vocab import FastText\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否使用gpu\n",
    "use_cuda=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(x):\n",
    "    record=x[\"result\"]\n",
    "    t=''.join([str(i[\"type\"]) for i in record])\n",
    "    detail=''.join([str(i[\"detail\"]) for i in record])\n",
    "    other=''.join([str(i[\"other\"]) for i in record])\n",
    "    return \"\".join([t,detail,other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fasttext(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fasttext,self).__init__()\n",
    "        self.net=torch.nn.Sequential(\n",
    "        torch.nn.Linear(300,256),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(256,32),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(32,2),\n",
    "        torch.nn.Softmax(dim=1))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram(x):\n",
    "    #需要改一下torchtext的源码\n",
    "    #找见所安装包下的vocab.py 410行\n",
    "    #url_base替换成 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.{}.vec'\n",
    "    vectors=FastText(language=\"zh\",url_base='https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.{}.vec')\n",
    "    xx=[]\n",
    "    for i in range(len(x)-1):\n",
    "        xx+=[x[i]+x[i+1]]\n",
    "    if use_cuda:\n",
    "        return torch.mean(torch.stack(list(map(lambda y:vectors[y],xx))),dim=0).to(\"cuda\")\n",
    "    else:\n",
    "        return torch.mean(torch.stack(list(map(lambda y:vectors[y],xx))),dim=0).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vscode csv to json插件转换的\n",
    "data_n=pd.read_json('/home/yuanmanjie/che300/negative_500.json',orient='records')\n",
    "data_p=pd.read_json('/home/yuanmanjie/che300/positive_500.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n[\"data\"]=data_n.iloc[:,1].map(get_text)\n",
    "data_p[\"data\"]=data_p.iloc[:,1].map(get_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data_n,data_p])\n",
    "data[\"embed\"]=data[\"data\"].map(bigram)\n",
    "data=data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存一下避免之后重跑上面的代码 很耗时……\n",
    "data.to_excel(r\"processed_data.xlsx\",index=0)\n",
    "data=pd.read_excel(r\"processed_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2dec2670225b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#ones=torch.sparse.torch.eye(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got str"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    train_x=torch.stack(list(data[\"embed\"]),dim=0).to(\"cuda\")\n",
    "    train_y=torch.tensor(list(data[\"label\"])).long().to(\"cuda\")\n",
    "else:\n",
    "    train_x=torch.stack(list(data[\"embed\"]),dim=0)\n",
    "    train_y=torch.tensor(list(data[\"label\"])).long()    \n",
    "#ones=torch.sparse.torch.eye(2)\n",
    "#train_y=ones.index_select(0,train_y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    loss=torch.nn.CrossEntropyLoss(weight=torch.tensor([1.,5.]).to(\"cuda\"))\n",
    "else:\n",
    "    loss=torch.nn.CrossEntropyLoss(weight=torch.tensor([1.,5.])\n",
    "#loss=torch.nn.MSELoss()\n",
    "epoch_n=1000\n",
    "learning_rate=1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model=fasttext().to(\"cuda\")\n",
    "else:\n",
    "    model=fasttext()\n",
    "optimzer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain_x=train_x[:800]\n",
    "ttrain_y=train_y[:800]\n",
    "pre_x=train_x[800:]\n",
    "pre_y=train_y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(y,pred):\n",
    "    l=loss(pred,y)\n",
    "    print(\"Loss:{:.4f}\".format(l.data),end='')\n",
    "    ly=pred[:,0]<pred[:,1]\n",
    "    TP=int(((y==1)&(ly==1)).sum())\n",
    "    TN=int(((y==0)&(ly==0)).sum())\n",
    "    FN=int(((y==1)&(ly==0)).sum())\n",
    "    FP=int(((y==0)&(ly==1)).sum())\n",
    "    if TP+FN!=0:\n",
    "        r=TP/(TP+FN)\n",
    "    else:\n",
    "        r=-1\n",
    "    if TP+FP!=0:\n",
    "        p=TP/(TP+FP)\n",
    "    else:\n",
    "        p=-1\n",
    "    print(\"p:{:.4f}\".format(p),end='')\n",
    "    print(\"r:{:.4f}\".format(r),end='')\n",
    "    if r>=0 and p >=0:\n",
    "        print(\"acc:{:.4f}\".format((TP+TN)/(TP+FP+FN+TN)),end='')\n",
    "    if r!=0 or p!=0:\n",
    "        print(\"F1:{:.4f}\".format(2*r*p/(r+p)),end='')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te(m,mode=0):\n",
    "    if mode==0:\n",
    "        pred=m(pre_x)\n",
    "        test(pre_y,pred)\n",
    "    else:\n",
    "        pred=m(ttrain_x)\n",
    "        test(ttrain_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Loss:0.3876\n",
      "training set:Loss:0.3876p:0.7219r:0.9899acc:0.8063F1:0.8349\n",
      "test set:Loss:0.4143p:0.6993r:0.9615acc:0.7650F1:0.8097\n",
      "Epoch:100,Loss:0.3861\n",
      "training set:Loss:0.3861p:0.7273r:0.9899acc:0.8113F1:0.8385\n",
      "test set:Loss:0.4145p:0.7042r:0.9615acc:0.7700F1:0.8130\n",
      "Epoch:200,Loss:0.3848\n",
      "training set:Loss:0.3848p:0.7300r:0.9899acc:0.8137F1:0.8403\n",
      "test set:Loss:0.4148p:0.6993r:0.9615acc:0.7650F1:0.8097\n",
      "Epoch:300,Loss:0.3835\n",
      "training set:Loss:0.3835p:0.7382r:0.9899acc:0.8213F1:0.8457\n",
      "test set:Loss:0.4152p:0.6993r:0.9615acc:0.7650F1:0.8097\n",
      "Epoch:400,Loss:0.3823\n",
      "training set:Loss:0.3823p:0.7410r:0.9899acc:0.8237F1:0.8476\n",
      "test set:Loss:0.4162p:0.6972r:0.9519acc:0.7600F1:0.8049\n",
      "Epoch:500,Loss:0.3814\n",
      "training set:Loss:0.3814p:0.7438r:0.9899acc:0.8263F1:0.8494\n",
      "test set:Loss:0.4171p:0.6972r:0.9519acc:0.7600F1:0.8049\n",
      "Epoch:600,Loss:0.3807\n",
      "training set:Loss:0.3807p:0.7438r:0.9899acc:0.8263F1:0.8494\n",
      "test set:Loss:0.4181p:0.7021r:0.9519acc:0.7650F1:0.8082\n",
      "Epoch:700,Loss:0.3800\n",
      "training set:Loss:0.3800p:0.7452r:0.9899acc:0.8275F1:0.8503\n",
      "test set:Loss:0.4192p:0.7021r:0.9519acc:0.7650F1:0.8082\n",
      "Epoch:800,Loss:0.3793\n",
      "training set:Loss:0.3793p:0.7467r:0.9899acc:0.8287F1:0.8512\n",
      "test set:Loss:0.4201p:0.7021r:0.9519acc:0.7650F1:0.8082\n",
      "Epoch:900,Loss:0.4827\n",
      "training set:Loss:0.4827p:0.4950r:1.0000acc:0.4950F1:0.6622\n",
      "test set:Loss:0.4679p:0.5226r:1.0000acc:0.5250F1:0.6865\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    y_pred=model(ttrain_x)\n",
    "    #print(y_pred)\n",
    "    l=loss(y_pred,ttrain_y)\n",
    "    if epoch%100==0:\n",
    "        print(\"Epoch:{},Loss:{:.4f}\".format(epoch,l.data))\n",
    "#     if epoch%100==0:\n",
    "        print(\"training set:\",end='')\n",
    "        te(model,1)\n",
    "        print(\"test set:\",end='')\n",
    "        te(model,0)\n",
    "        \n",
    "    optimzer.zero_grad()\n",
    "    l.backward()\n",
    "    #for param in model.parameters():\n",
    "    #    param.data-=param.grad.data*lr\n",
    "    optimzer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.5436\n",
      "p:0.7387\n",
      "r:0.8039\n",
      "acc:0.7550\n",
      "F1:0.7700\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for keyword argument 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-966e4d1f8cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.{}.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for keyword argument 'url'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0448,  1.1315, -0.7133,  0.2258,  0.9335, -0.1075, -0.8293, -0.1014,\n",
       "         0.3125, -0.1808,  0.8690,  0.1376,  1.9608, -1.1774,  0.2758, -0.7833,\n",
       "         1.1592, -0.3257, -1.3767, -1.1352, -0.8417,  1.3421,  1.3970,  0.1438,\n",
       "         1.0305, -0.4318,  1.2344,  0.2403,  0.7931,  0.3357,  1.4705, -1.1395,\n",
       "        -1.0604, -0.7375, -1.1902,  1.2162,  1.1020, -0.5441,  0.4227,  1.5478,\n",
       "         1.2682,  1.1972,  1.5960, -1.4509, -0.6763, -0.6861, -1.0299, -0.2203,\n",
       "         0.8798, -1.0690,  1.4894, -0.7151, -0.5835, -0.5646,  0.2686, -1.0477,\n",
       "        -1.1429, -1.5862, -4.3141,  0.9801,  1.1265, -0.1549,  0.9980,  1.2995,\n",
       "         0.1297,  1.2300, -1.0817, -0.3750, -0.7593, -0.2319,  1.6325, -0.7496,\n",
       "         1.4902, -0.2878, -1.1078,  0.6162, -0.1616, -1.5167, -0.4369, -1.1276,\n",
       "        -0.2838,  0.4398,  1.2792, -0.8688, -0.9199, -0.8966,  0.2349,  0.8369,\n",
       "         0.2281, -1.3591, -0.8649,  0.8512, -0.2739, -0.3199, -0.9880,  1.2700,\n",
       "         0.7796,  0.4996,  0.0162,  0.1926,  0.0064,  0.6786, -0.6576,  1.2514,\n",
       "        -1.1793,  0.8050, -0.1818, -0.6363, -1.0918, -0.0776,  0.3360, -0.8303,\n",
       "         0.2078,  0.5647,  0.4178,  0.2740, -0.5504,  0.4866, -1.0433, -0.7282,\n",
       "        -0.9828,  0.7862,  0.8079, -0.0490, -0.9932, -1.1181,  0.9175,  1.1315,\n",
       "        -1.3129,  0.2305,  0.6824,  0.2743, -1.1638,  1.1258, -1.4157,  0.5125,\n",
       "        -0.4327, -0.1086, -1.4073, -0.4153, -0.1768,  1.1221,  1.4655, -1.6009,\n",
       "        -0.8438,  0.5268, -1.6816,  0.0802, -0.8297, -0.1887,  0.7795,  1.1550,\n",
       "        -0.5250,  0.4038,  0.7953, -0.8839,  0.8098, -0.4351, -0.2667,  0.8317,\n",
       "         0.5389,  0.2919,  0.7294, -0.0238, -0.3054, -0.2092, -0.1055,  1.0187,\n",
       "         0.6469,  0.5618,  1.0153,  0.3012,  1.4824, -0.3684,  0.0460, -0.3622,\n",
       "         1.3249,  0.9840, -0.2106, -0.3352, -0.7786, -0.9114,  0.1560,  0.2049,\n",
       "        -0.5800,  1.0778, -0.0497, -0.5495, -0.9326,  0.6498, -0.0595, -0.1978,\n",
       "        -0.4716, -0.7926, -0.1677, -0.4828, -0.9046, -1.0157, -0.0701,  0.3660,\n",
       "        -0.4733, -0.4448, -0.1817, -1.0310,  0.0335, -0.2475,  0.5656, -0.7694,\n",
       "        -0.4331,  0.5200, -0.9156,  0.3814, -0.6712,  0.3658, -0.8636,  0.4019,\n",
       "         0.2836,  0.1526,  1.1973,  0.7835, -0.5898,  0.4878,  0.7761, -0.1778,\n",
       "        -1.1131,  0.9384, -0.6131, -0.4617, -0.9627,  0.5302, -0.9388,  0.0689,\n",
       "         0.5111, -0.5983, -0.2417,  1.0738,  0.6771, -1.5477, -0.2364, -0.2785,\n",
       "         0.6020, -0.8645,  0.8385, -0.1454, -0.5581, -0.2537, -0.7145, -0.4284,\n",
       "        -0.8248,  0.2116, -0.5542, -0.3428, -1.2109,  0.6109, -0.4970,  0.0464,\n",
       "         0.6357,  0.8388, -1.5108,  0.0134,  0.3709, -0.2977, -0.5582, -0.2909,\n",
       "        -0.7987, -0.1937, -1.0668, -0.7972, -1.9858, -0.9750, -0.2380,  0.2096,\n",
       "         0.9459, -1.0919,  0.0855, -0.1528,  0.0674,  0.7252, -0.1717, -0.8994,\n",
       "         0.5953,  2.1065,  0.1816,  1.1537,  0.3286, -0.5354,  0.6124,  0.5234,\n",
       "        -0.6926, -0.0593, -1.0989, -1.3567, -0.6844, -0.8544,  0.1081, -0.8151,\n",
       "         0.2655,  0.6625,  1.3987, -0.0051])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
